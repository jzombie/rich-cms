# Links of Interest

1. â€œNo inventions; no innovations," a History of US Steel: https://www.construction-physics.com/p/no-inventions-no-innovations-a-history
2. Why are Apple silicon VMs so different?: https://eclecticlight.co/2023/12/29/why-are-apple-silicon-vms-so-different/
3. How Arm conquered the chip market without making a single chip: https://www.theverge.com/23373371/arm-chips-chip-shortage-ceo-rene-haas-tech-intel-apple-decoder
4. The Random Transformer: https://osanseviero.github.io/hackerllama/blog/posts/random_transformer/
5. You don't need analytics on your blog: https://blog.yossarian.net/2023/12/24/You-dont-need-analytics-on-your-blog
6. On building a semantic search: https://vickiboykis.com/2024/01/05/retro-on-viberary/
7. Some good pointers on lasting web pages: https://jeffhuang.com/designed_to_last/
8. Simple lasts longer: https://newsletter.pnote.eu/p/simple-lasts-longer
9. Guide to Self-Attention: https://twiecki.io/blog/2024/01/04/
10. Building a Container from Scratch in Rust: https://brianshih1.github.io/mini-container/
11. Nice looking blog w/ contents: https://matthewsanabria.dev/posts/no-shell-for-you-container/#difficulties-of-minimal-container-images
12. Setting up Windows 11 w/o Microsoft Account: https://www.tomshardware.com/how-to/install-windows-11-without-microsoft-account
13. Follow RSS across the web: https://openrss.org/
14. (Machine Learning Engineering Open Book
 ): https://github.com/stas00/ml-engineering
15. Why is machine learning hard?: https://ai.stanford.edu/~zayd/why-is-machine-learning-hard.html
16. Machine learning is still too hard for software engineers: https://news.ycombinator.com/item?id=39109469
17. Build an LLM (from Scratch): https://github.com/rasbt/LLMs-from-scratch
18. Goodhart's law: https://en.wikipedia.org/wiki/Goodhart%27s_law ("When a measure becomes a target, it ceases to be a good measure.")
19. Technology is the problem )includes mention of "doped silicon user interfaces"): https://www.shyamsankar.com/p/technology-is-the-problem
20. (I just like the heading fonts): https://joshstrange.com/2019/09/26/my-mac-apps/
21. This site's auto-generated sitemap: https://richcms.zenosmosis.com/sitemap.xml
22. Running Local LLMs and VLMs on the Raspberri Pi: https://towardsdatascience.com/running-local-llms-and-vlms-on-the-raspberry-pi-57bd0059c41a
23. Adding full-text search to a static site: https://www.markusdosch.com/2022/05/adding-full-text-search-to-a-static-site-no-backend-needed/
24. AI-driven search engine: https://www.perplexity.ai/
25. Building container images using no tools: https://ravichaganti.com/blog/2022-11-28-building-container-images-using-no-tools/
26. (A search engine in 80 lines of Python [give or take])
    - https://news.ycombinator.com/item?id=39293050
    - https://www.alexmolas.com/2024/02/05/a-search-engine-in-80-lines.html
    - Related [found in same HN discussion]: https://github.com/softwaredoug/searcharray
27. Aligning an LLM with human preferences (I like the "trainer" API design, at first glance): https://datadreamer.dev/docs/latest/pages/get_started/quick_tour/aligning.html
28. Self-balancing cube: https://willempennings.nl/balancing-cube/
29. StatQuest: An epic journey through statistics and machine learning: https://statquest.org/
30. Fractals in Neural Network Hyperparameter Tuning: https://www.linkedin.com/posts/liorsinclair_this-is-incredible-fractal-patterns-were-ugcPost-7162848575834501125-TuDV?utm_source=share&utm_medium=member_desktop (related paper: https://arxiv.org/abs/2402.06184)
31. AdaBelief Optimizer: https://arxiv.org/abs/2010.07468 (source code: https://github.com/juntang-zhuang/Adabelief-Optimizer)
32. [Mostly non-optimized] Machine Learning Algorithms in Python: https://github.com/rushter/MLAlgorithms
33. Fix loose git object corruption: https://accio.github.io/programming/2021/06/16/fix-loose-objects-in-git.html
34. GPT in 500 lines of SQL: https://explainextended.com/2023/12/31/happy-new-year-15/
35. GPT in 60 lines of NumPy (Hacker News): https://news.ycombinator.com/item?id=34726115
36. Emergent mind (monitors social mdedia for discussions about recently-published [arXiv](https://arxiv.org/) papers): https://www.emergentmind.com/
37. Accelerating Generative AI with PyTorch II: GPT, Fast: https://pytorch.org/blog/accelerating-generative-ai-2/
38. Keras (MLX backend): https://github.com/keras-team/keras/pull/18962
39. Kaggle Finance Dataset (search): https://www.kaggle.com/search?q=finance+dataset
40. Eloquent JavaScript 4th Edition (2024): https://news.ycombinator.com/item?id=39629044
41. Famous algorithmic patterns and their everyday usage: https://www.linkedin.com/posts/arslanahmad_systemdesign-softwarearchitecture-softwaredevelopment-activity-7170661917621936128-qwFf?utm_source=share&utm_medium=member_desktop
42. Big-O cheat sheet: https://www.linkedin.com/posts/arslanahmad_codinginterview-timecomplexity-activity-7167956367599763456-4H4t?utm_source=share&utm_medium=member_desktop
43. Data structures worth knowing: https://www.linkedin.com/posts/arslanahmad_systemdesign-coding-interviewtips-activity-7171064213992402944-0qSv?utm_source=share&utm_medium=member_desktop
44. Exponential smoothing animation tricks (with code examples): https://lisyarus.github.io/blog/programming/2023/02/21/exponential-smoothing.html
45. I Was a Statistics Professor. I Used Sports Betting to Retire at 43: https://www.newsweek.com/i-was-statistics-professor-i-used-sports-betting-retire-43-1858974
46. Linear warmup with cosine annealing (machine learning): https://github.com/rasbt/LLMs-from-scratch/blob/main/appendix-D/01_main-chapter-code/appendix-D.ipynb
47. An invention to silence reggaeton with artificial intelligence: https://english.elpais.com/technology/2024-03-17/an-invention-to-silence-reggaeton-with-artificial-intelligence.html
48. Sam's Journey (new NES game): https://news.ycombinator.com/item?id=39730787
49. Grok-1 (xAI model): https://github.com/xai-org/grok-1
50. Spleeter (audio source separation library with pretrained models; stem separation; vocals / drums / bass / piano / other separation): https://github.com/deezer/spleeter/wiki/2.-Getting-started#using-docker-image
51. Free Spark Resources: https://www.linkedin.com/posts/shubhamwadekar_spark-data-dataengineering-activity-7178246825999556609-CjSI/?utm_source=share&utm_medium=member_android
52. AssemblyScript: A TypeScript-like language for WebAssembly: https://www.assemblyscript.org/
53. Radios, how do they work? (A brief introduction to antennas, superheterodyne receivers, and signal modulation schemes): https://lcamtuf.substack.com/p/radios-how-do-they- (HN discussion: https://news.ycombinator.com/item?id=39813679)
54. Modern AI Discourse is Talentless Business Students Trying to Give Young Engineers PTSD: https://www.timokats.xyz/?content=writings/aiblog
55. Reading and Writing WAV Files in Python: https://realpython.com/python-wav-files/
56. Conversation as an Interface (2016): https://annjose.com/post/conversation-as-interface/
57. Svelte parses HTML all wrong: https://github.com/sveltejs/svelte/issues/11052
58. Find Median from Data Stream: https://leetcode.com/problems/find-median-from-data-stream/ (maybe it could be useful for implementation of RobustScaler partial fit [open-source the solution?]; related StackOverflow discussion: https://stackoverflow.com/questions/57291876/robustscaler-partial-fit-similar-to-minmaxscaler-or-standardscaler)
59. LeetCode (25 questions to cover the most important patterns): https://www.linkedin.com/posts/alexandre-zajac_softwareengineering-coding-programming-activity-7181538559999238144-lwW8?utm_source=share&utm_medium=member_desktop

## Papers of Interest

1. Fractals in Neural Network Hyperparameter Tuning: https://arxiv.org/abs/2402.06184
2. Deep Reinforcement Learning for Quantitative Trading: https://arxiv.org/abs/2312.15730v1
3. Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping: https://arxiv.org/html/2402.14083v1
4. [Apple's multi-modal, foundational model] MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training: https://arxiv.org/abs/2403.09611 (relevant Hacker News discussion: https://news.ycombinator.com/item?id=39722498)
5. Can Large Language Models Reason and Plan? (PDF): https://arxiv.org/pdf/2403.04121.pdf

## Books of Interest

1. Build a Large Language Model (From Scratch) [currently not published as of March 16, 2024]: https://www.manning.com/books/build-a-large-language-model-from-scratch?utm_source=raschka&utm_medium=affiliate&utm_campaign=book_raschka_build_12_12_23&a_aid=raschka&a_bid=4c2437a0&chan=mm_github

## Videos of Interest

- Building transformers from scratch: https://www.youtube.com/watch?v=kCc8FmEb1nY
- AI beats multiple World Records in Trackmania (reinforcement learning): https://www.youtube.com/watch?v=kojH8a7BW04
- PyTorch for Deep Learning & Machine Learning (long, ~24-hour video): https://www.youtube.com/watch?v=V_xro1bcAuA
- But what is a GPT? Visual intro to Transformers: https://www.youtube.com/watch?v=wjZofJX0v4M
